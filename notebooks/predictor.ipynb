{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "from src.config.config import load_config\n",
    "\n",
    "class MLflowInferenceLogger:\n",
    "    \"\"\"Handles MLflow logging during inference\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        mlflow_config = load_config('configs/mlflow.yaml')\n",
    "        mlflow.set_tracking_uri(mlflow_config['tracking']['uri'])\n",
    "        mlflow.set_experiment(f\"{mlflow_config['tracking']['experiment_name']}-inference\")\n",
    "        \n",
    "    def log_frame(self, frame, predictions, frame_count):\n",
    "        \"\"\"Log frame and predictions\"\"\"\n",
    "        with mlflow.start_run(run_name=f\"inference-{datetime.now().strftime('%Y%m%d-%H%M%S')}\", nested=True):\n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                'inference/num_detections': len(predictions),\n",
    "                'inference/avg_confidence': np.mean([p.conf for p in predictions]) if predictions else 0\n",
    "            }, step=frame_count)\n",
    "            \n",
    "            # Log sample frames periodically\n",
    "            if frame_count % self.config['output']['save_interval'] == 0:\n",
    "                self._save_frame(frame, predictions, frame_count)\n",
    "    \n",
    "    def _save_frame(self, frame, predictions, frame_count):\n",
    "        \"\"\"Save annotated frame as MLflow artifact\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_dir = os.path.join(self.config['output']['save_dir'], str(frame_count))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save original and processed frames\n",
    "        orig_path = os.path.join(output_dir, f\"original_{timestamp}.jpg\")\n",
    "        processed_path = os.path.join(output_dir, f\"processed_{timestamp}.jpg\")\n",
    "        \n",
    "        cv2.imwrite(orig_path, frame)\n",
    "        processed_frame = self._annotate_frame(frame.copy(), predictions)\n",
    "        cv2.imwrite(processed_path, processed_frame)\n",
    "        \n",
    "        mlflow.log_artifacts(output_dir, f\"frames/{frame_count}\")\n",
    "\n",
    "class GlassesDetectionPipeline:\n",
    "    def __init__(self, config_path='configs/app_config.yaml'):\n",
    "        self.config = load_config(config_path)\n",
    "        self.model = self._load_model()\n",
    "        self.class_names = self.model.names\n",
    "        self.glasses_class_id = self._get_glasses_class_id()\n",
    "        self.logger = MLflowInferenceLogger(self.config)\n",
    "    \n",
    "    # ... (keep existing _load_model, _get_glasses_class_id methods)\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        results = self.model(frame, verbose=False)\n",
    "        glasses_detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls == self.glasses_class_id:\n",
    "                    glasses_detections.append({\n",
    "                        'bbox': box.xyxy[0].tolist(),\n",
    "                        'conf': box.conf.item(),\n",
    "                        'cls': box.cls.item()\n",
    "                    })\n",
    "        \n",
    "        return glasses_detections\n",
    "    \n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.config['camera']['source'])\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            detections = self.process_frame(frame)\n",
    "            self.logger.log_frame(frame, detections, frame_count)\n",
    "            \n",
    "            # Visualize and display\n",
    "            processed_frame = frame.copy()\n",
    "            for det in detections:\n",
    "                x1, y1, x2, y2 = map(int, det['bbox'])\n",
    "                processed_frame[y1:y2, x1:x2] = 0  # Black out glasses\n",
    "            \n",
    "            cv2.imshow('Glasses Detection', processed_frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = GlassesDetectionPipeline()\n",
    "    pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from typing import Tuple, Dict, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from src.config.config import load_config\n",
    "\n",
    "class GlassesDetectionPipeline:\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.model = self._load_model()\n",
    "        self.class_names = self.model.names\n",
    "        self.glasses_class_id = self._get_glasses_class_id()\n",
    "        mlflow_config = load_config('configs/mlflow.yaml')\n",
    "        mlflow.set_tracking_uri(mlflow_config['tracking']['uri'])\n",
    "        mlflow.set_experiment(f\"{mlflow_config['tracking']['experiment_name']}-inference\")\n",
    "        \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            model = YOLO(self.config['inference']['path'])\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Model loading failed: {e}\")\n",
    "    \n",
    "    def _get_glasses_class_id(self) -> int:\n",
    "        \"\"\"Find glasses class ID in model\"\"\"\n",
    "        for class_id, class_name in self.class_names.items():\n",
    "            if 'glass' in class_name.lower():\n",
    "                return class_id\n",
    "        raise ValueError(\"Glasses class not found in model\")\n",
    "    \n",
    "    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"Process single frame for glasses detection\"\"\"\n",
    "        results = self.model(frame, verbose=False)\n",
    "        metrics = {'glasses_detected': False, 'confidence': 0.0}\n",
    "        \n",
    "        annotated_frame = frame.copy()\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls == self.glasses_class_id:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                    annotated_frame[y1:y2, x1:x2] = 0  # Black out glasses\n",
    "                    metrics.update({\n",
    "                        'glasses_detected': True,\n",
    "                        'confidence': float(box.conf),\n",
    "                        'bbox': [x1, y1, x2, y2]\n",
    "                    })\n",
    "                    confidence = float(box.conf)\n",
    "                    class_id = int(box.cls[0])\n",
    "                    class_name = self.model.names[class_id]\n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    label = f\"{class_name} {confidence:.2f}\"\n",
    "                    cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "        \n",
    "        return annotated_frame, metrics\n",
    "    # def process_frame(self, frame):\n",
    "    # # Run the YOLO model on the frame\n",
    "    #     results = self.model(frame)\n",
    "\n",
    "    #     # Iterate over detections and draw bounding boxes\n",
    "    #     for result in results[0].boxes:\n",
    "    #         x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "    #         class_id = int(result.cls[0])\n",
    "    #         confidence = result.conf[0]\n",
    "    #         class_name = self.model.names[class_id]\n",
    "\n",
    "    #         # Draw bounding box and label\n",
    "    #         cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    #         label = f\"{class_name} {confidence:.2f}\"\n",
    "    #         cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    #     return frame\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main pipeline execution\"\"\"\n",
    "        cap = cv2.VideoCapture(self.config['camera']['source'])\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.config['camera']['width'])\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.config['camera']['height'])\n",
    "        #set mlflow experiment\n",
    "        #mlflow.set_tracking_uri(self.config['mlflow']['tracking_uri'])\n",
    "        #mlflow.set_experiment(self.config['mlflow']['experiment_name'])\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            self._log_parameters()\n",
    "            frame_count = 0\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                processed_frame, metrics = self.process_frame(frame)\n",
    "                self._log_metrics(metrics, frame_count)\n",
    "\n",
    "                #processed_frame= self.process_frame(frame)\n",
    "                cv2.imshow('Glasses Detection', processed_frame)\n",
    "                self._save_output(processed_frame, frame_count)\n",
    "                \n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "            \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    def _log_parameters(self):\n",
    "        \"\"\"Log parameters to MLflow\"\"\"\n",
    "        mlflow.log_params({\n",
    "            'model': os.path.basename(self.config['model']['path']),\n",
    "            'confidence_threshold': self.config['model']['confidence_threshold'],\n",
    "            'resolution': f\"{self.config['camera']['width']}x{self.config['camera']['height']}\"\n",
    "        })\n",
    "    \n",
    "    def _log_metrics(self, metrics: dict, frame_count: int):\n",
    "        \"\"\"Log metrics to MLflow\"\"\"\n",
    "        mlflow.log_metrics({\n",
    "            'glasses_detected': int(metrics['glasses_detected']),\n",
    "            'confidence': metrics.get('confidence', 0),\n",
    "        }, step=frame_count)\n",
    "    \n",
    "    def _save_output(self, frame: np.ndarray, frame_count: int):\n",
    "        \"\"\"Save output frames periodically\"\"\"\n",
    "        if frame_count % self.config['output']['save_interval'] == 0:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = os.path.join(\n",
    "                self.config['output']['save_dir'],\n",
    "                f\"frame_{timestamp}_{frame_count}.jpg\"\n",
    "            )\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            #mlflow.log_artifact(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.config import load_config\n",
    "config = load_config()\n",
    "# Initialize pipeline\n",
    "pipeline = GlassesDetectionPipeline(config)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gregarious-mole-193 at: http://127.0.0.1:5000/#/experiments/602706232016475332/runs/771813cc9a1a4e0ba00d462da92a96c4\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/602706232016475332\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Release resources and close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a blank image\n",
    "image = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "cv2.imshow(\"Test Window\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.1.1\n",
      "OpenCV version: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
